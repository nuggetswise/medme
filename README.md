# MedMe Copilot Demo

A Streamlit-based demonstration of LLM-powered clinical workflow assistance for pharmacy operations, designed for Senior Product Manager evaluation at MedMe Health.

## 🎯 Overview

This demo showcases intelligent automation features that enhance pharmacy efficiency and patient care through LLM-powered insights:

- **Patient Insight Recommender**: Identifies patients due for clinical follow-ups
- **Schedule Optimizer**: Maximizes revenue through strategic appointment scheduling
- **Message Generator**: Creates personalized patient communications
- **Request Triage**: Intelligently routes and prioritizes patient inquiries

## 🚀 Features

### 🤖 LLM-Powered Intelligence
- **Minimal Code Maintenance**: LLMs handle the complex reasoning
- **Clinical Knowledge**: Built-in medical guidelines and best practices
- **Natural Language Understanding**: Intelligent analysis of patient data and messages
- **Personalization**: Context-aware recommendations and messaging

### 📊 Key Modules

1. **Patient Insights**
   - Age and condition-based recommendations
   - Revenue impact analysis
   - Clinical priority scoring
   - Insurance-specific suggestions

2. **Schedule Optimization**
   - Revenue-maximizing slot allocation
   - Service upgrade recommendations
   - Time investment analysis
   - Strategic reasoning

3. **Message Generation**
   - Personalized patient communications
   - Tone and urgency adaptation
   - Clinical context integration
   - Multi-channel support

4. **Request Triage**
   - Natural language understanding
   - Sentiment and urgency analysis
   - Intelligent action recommendations
   - Auto-routing capabilities

## 🛠️ Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd medme_copilot_demo
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the application**
   ```bash
   streamlit run app.py
   ```

## 🎮 Quick Start

### Mac/Linux
```bash
chmod +x run_demo.sh
./run_demo.sh
```

### Windows
```bash
run_demo.bat
```

The app will be available at `http://localhost:8501`

## 📋 Requirements

- Python 3.8+
- Streamlit 1.28.0+
- Pandas 2.0.0+
- **No external API keys required!**

## 🏗️ Architecture

```
medme_copilot_demo/
├── app.py                 # Main Streamlit application with LLM prompts
├── requirements.txt       # Minimal Python dependencies
├── README.md             # This file
├── run_demo.sh           # Mac/Linux startup script
└── run_demo.bat          # Windows startup script
```

## 🧠 LLM-Powered Features

### Intelligent Prompting
- **Clinical Reasoning**: LLM-style analysis of patient data
- **Revenue Optimization**: Strategic scheduling recommendations
- **Message Analysis**: Natural language understanding
- **Personalization**: Context-aware recommendations

### Key Capabilities
- **Risk Scoring**: Patient risk assessment algorithms
- **Revenue Optimization**: Strategic scheduling recommendations
- **Message Analysis**: Natural language understanding
- **Clinical Reasoning**: Evidence-based recommendations

## 🎯 Demo Scenarios

### For Product Managers
1. **Patient Insights**: Show how LLMs identify revenue opportunities
2. **Schedule Optimization**: Demonstrate revenue impact of intelligent scheduling
3. **Message Generation**: Highlight personalized communication capabilities
4. **Request Triage**: Showcase operational efficiency improvements

### Business Impact
- **Revenue Growth**: $2,340 potential impact demonstrated
- **Time Savings**: 4.2 hours saved per week
- **Patient Engagement**: Personalized communication strategies
- **Operational Efficiency**: Intelligent workflow automation

## 🔧 Configuration

The demo uses a simplified LLM-powered approach:

- **LLM Intelligence**: Always available, no setup required
- **Minimal Maintenance**: LLMs handle complex reasoning
- **Demo Data**: Realistic patient and scheduling scenarios
- **Customizable Prompts**: Easy to modify for different use cases

## 📈 Performance Metrics

The demo includes realistic performance indicators:
- Patient analysis throughput
- Recommendation accuracy
- Revenue impact calculations
- Time savings estimates

## 🚀 Production Ready

This approach is designed for easy production deployment:

1. **Replace LLM Simulation**: Connect to real LLM APIs (OpenAI, Anthropic, etc.)
2. **Add Real Data**: Integrate with pharmacy systems
3. **Scale Prompts**: Expand prompt library for more use cases
4. **Monitor Performance**: Track LLM response quality and costs

## 🤝 Contributing

This is a demonstration application. For production use, consider:
- Integration with real pharmacy systems
- HIPAA compliance measures
- LLM API cost optimization
- Additional clinical validations

## 📄 License

This demo is for evaluation purposes. Please contact MedMe Health for commercial licensing.

---

**Built for MedMe Health Product Manager Evaluation** 🏥 